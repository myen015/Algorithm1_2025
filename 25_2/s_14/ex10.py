# -*- coding: utf-8 -*-
"""ex10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ItmwiiZT2rUDDyfWdvoQW4ytNQJlE-73
"""

print("Problem 1: Complexity Classification\n")

complexity_classes = {
    "P": [
        "find max", "linear search", "shortest path (unweighted graph)", "matrix multiplication",
        "sorting of list", "Dijkstra (non-negative weights)", "BFS", "DFS", "merge sort", "quicksort"
    ],
    "NP-complete": [
        "Sudoku",
        "3-coloring of graph", "scheduling with conflicts",
        "Traveling Salesperson Problem", "Hamiltonian Cycle", "Clique"
    ],
    "NP-hard / NP": [
        "Cryptography", "factoring large integers"
    ],
    "NP-hard / uncomputable": [
        "Halting Problem", "Busy Beaver"
    ]
}

for cls, problems in complexity_classes.items():
    print(f"{cls}:")
    for p in problems:
        print(f"  - {p}")
    print()

# -----------------------------
# Problem 2: Bayes Theorem
# -----------------------------
print("\nProblem 2: Bayes Theorem\n")

# Given probabilities
P_disease = 0.001      # 0.1%
P_no_disease = 0.999
P_pos_given_disease = 0.99
P_pos_given_no_disease = 0.01

# Total probability of positive test
P_pos = P_pos_given_disease * P_disease + P_pos_given_no_disease * P_no_disease

# Probability patient actually has the disease given positive test
P_disease_given_pos = (P_pos_given_disease * P_disease) / P_pos

print(f"Probability the patient actually has the disease given positive test: {P_disease_given_pos:.2%}")

# -----------------------------
# Problem 3: Shannon Entropy
# -----------------------------
print("\nProblem 3: Shannon Entropy\n")
import math

def shannon_entropy(prob_heads):
    p_h = prob_heads
    p_t = 1 - prob_heads
    H = 0
    if p_h > 0:
        H -= p_h * math.log2(p_h)
    if p_t > 0:
        H -= p_t * math.log2(p_t)
    return H

coins = {
    "Fair Coin (50% heads)": 0.5,
    "Biased Coin (99% heads)": 0.99,
    "Biased Coin (1% heads)": 0.01
}

for name, p in coins.items():
    H = shannon_entropy(p)
    print(f"{name}: Entropy = {H:.3f} bits")