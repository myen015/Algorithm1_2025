# -*- coding: utf-8 -*-
"""Ex3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBpJhMRN_iG5JCOHL0kVlqgteS7Huv79
"""

import numpy as np
import matplotlib.pyplot as plt
import math
from math import comb

# ==============================================================
# PROBLEM 1 — Fibonacci SuperFast
# ==============================================================
print("=== PROBLEM 1: Fibonacci SuperFast! ===")

def matrix_mult(A, B):
    return [
        [A[0][0]*B[0][0] + A[0][1]*B[1][0],
         A[0][0]*B[0][1] + A[0][1]*B[1][1]],
        [A[1][0]*B[0][0] + A[1][1]*B[1][0],
         A[1][0]*B[0][1] + A[1][1]*B[1][1]]
    ]

def matrix_power(M, n):
    if n == 0:
        return [[1, 0], [0, 1]]  # Identity matrix
    if n == 1:
        return M
    half = matrix_power(M, n // 2)
    half_sq = matrix_mult(half, half)
    return matrix_mult(M, half_sq) if n % 2 else half_sq

def fibonacci_fast(n):
    if n == 0:
        return 0
    M = [[1, 1], [1, 0]]
    Mn = matrix_power(M, n - 1)
    return Mn[0][0]  # F(n)

# Example:
for i in range(1, 11):
    print(f"F({i}) = {fibonacci_fast(i)}")

print("\nTime Complexity: T(n) = T(n/2) + O(1) → O(log n)")
print("Each step performs constant-size (2x2) matrix multiplications.\n")

# ==============================================================
# PROBLEM 2 — 0/1 Knapsack Algorithm
# ==============================================================
print("=== PROBLEM 2: 0/1 Knapsack ===")

# Example items (weights, values)
weights = [2, 3, 4, 5]
values = [3, 4, 5, 6]
W = 8  # total capacity
n = len(values)

def knapsack_dp(weights, values, W):
    """Standard DP solution: O(nW) time, O(nW) space."""
    n = len(weights)
    dp = [[0]*(W+1) for _ in range(n+1)]
    for i in range(1, n+1):
        for w in range(W+1):
            if weights[i-1] <= w:
                dp[i][w] = max(dp[i-1][w],
                               dp[i-1][w-weights[i-1]] + values[i-1])
            else:
                dp[i][w] = dp[i-1][w]
    return dp[n][W]

def knapsack_optimized(weights, values, W):
    """Optimized DP: O(nW) time, O(W) space."""
    dp = [0]*(W+1)
    for i in range(len(weights)):
        for w in range(W, weights[i]-1, -1):
            dp[w] = max(dp[w], dp[w-weights[i]] + values[i])
    return dp[W]

print("Maximum value (2D DP):", knapsack_dp(weights, values, W))
print("Maximum value (Optimized 1D DP):", knapsack_optimized(weights, values, W))
print("Space Complexity Reduced to O(W)\n")

# ==============================================================
# PROBLEM 3 — NeuroComputing!
# ==============================================================
print("=== PROBLEM 3: NeuroComputing ===")

# 3.1 Generate random binary vectors
def generate_random_binary_vectors(num_vec=100, N=100, p=0.5):
    return (np.random.rand(num_vec, N) < p).astype(int)

# 3.2 Similarity functions
def sim_norm(x, y):
    num = (x & y).sum()
    denom = x.sum() * y.sum()
    return num / denom if denom > 0 else 0.0

def jaccard(x, y):
    inter = (x & y).sum()
    union = (x | y).sum()
    return inter / union if union > 0 else 0.0

# Generate 100 binary vectors of length N
N = 200
vecs = generate_random_binary_vectors(100, N)

# Compute pairwise Jaccard similarities
sims = []
for i in range(len(vecs)):
    for j in range(i+1, len(vecs)):
        sims.append(jaccard(vecs[i], vecs[j]))

# Plot histogram of similarities
plt.hist(sims, bins=30, color='skyblue', edgecolor='black')
plt.title(f"Pairwise Jaccard Similarities (N={N}, 100 vectors)")
plt.xlabel("Similarity")
plt.ylabel("Frequency")
plt.show()

print(f"Mean Jaccard similarity: {np.mean(sims):.4f}")
print("→ Distribution is approximately Gaussian due to Central Limit Theorem.\n")

# 3.3 Larger N experiment
for N_test in [100, 500, 1000]:
    vecs = generate_random_binary_vectors(100, N_test)
    sims = []
    for i in range(len(vecs)):
        for j in range(i+1, len(vecs)):
            sims.append(jaccard(vecs[i], vecs[j]))
    print(f"N={N_test}: Mean={np.mean(sims):.4f}, Std={np.std(sims):.4f}")
print("\nAs N increases, variance decreases → distribution becomes narrower.\n")

# 3.4 Sparse vectors count
N = 2000
w = 5
num_vectors = comb(N, w)
bits = math.log2(num_vectors)
print(f"For N={N}, w={w}:")
print(f"Number of possible sparse vectors = {num_vectors:.3e}")
print(f"Information capacity ≈ {bits:.3f} bits (~{bits/2000:.4f} bits/component)\n")

# 3.5 Capacity discussion (printed summary)
print("Capacity interpretation:")
print("- Combinatorial capacity: log2(C(N, w)) bits.")
print("- Larger N with fixed small w → exponentially many sparse vectors.")
print("- In associative memory terms, capacity ≈ number of distinct patterns storable without interference.\n")

print("=== END OF PROBLEM SET #3 ===")

cd /path/to/your/local/repository

cd /content/Algorithm1_2025

!git clone https://github.com/ChenHaaa/Algorithm1_2025.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Algorithm1_2025

!ls 25_2/s_14

!git add 25_2/s_14/Ex3.py

!ls 25_2/s_14

!mkdir -p /content/Algorithm1_2025/25_2/s_14