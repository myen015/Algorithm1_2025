{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fundamental Algorithm Techniques – Problem Set #10\n",
        "Problem 1. P, NP, NP-complete, NP-hard (4/10 pts)\n",
        "\n",
        "We classify each group of problems according to standard complexity classes.\n",
        "\n",
        "1. Find max, linear search, shortest path in unweighted graph, matrix multiplication\n",
        "\n",
        "All these problems can be solved in polynomial time.\n",
        "\n",
        "Finding a maximum or performing a linear search takes linear time.\n",
        "Shortest path in an unweighted graph can be solved using BFS in linear time.\n",
        "Matrix multiplication can be done in polynomial time.\n",
        "\n",
        "Therefore, all problems in this group belong to class P.\n",
        "\n",
        "2. Sorting a list, Dijkstra with non-negative weights, BFS, DFS, merge sort, quicksort\n",
        "\n",
        "All listed algorithms run in polynomial time and are efficiently solvable.\n",
        "\n",
        "Sorting algorithms such as merge sort and quicksort run in polynomial time.\n",
        "Graph traversal algorithms such as BFS and DFS are linear.\n",
        "Dijkstra’s algorithm with non-negative weights is polynomial.\n",
        "\n",
        "Thus, this entire group belongs to class P.\n",
        "\n",
        "3. Sudoku\n",
        "\n",
        "Sudoku (in the generalized form, not fixed 9×9) is a decision problem whose solution can be verified in polynomial time.\n",
        "\n",
        "It is known to be NP-complete, meaning:\n",
        "\n",
        "It belongs to NP\n",
        "\n",
        "Every problem in NP can be reduced to it in polynomial time\n",
        "\n",
        "4. Graph 3-coloring, scheduling with conflicts\n",
        "\n",
        "Graph 3-coloring asks whether a graph can be colored using three colors without conflicts.\n",
        "Scheduling with conflicts can be reduced to graph coloring.\n",
        "\n",
        "Both problems are classic NP-complete problems.\n",
        "\n",
        "5. Traveling Salesperson Problem, Hamiltonian Cycle, Clique\n",
        "\n",
        "These are canonical problems in complexity theory.\n",
        "\n",
        "Hamiltonian Cycle is NP-complete\n",
        "\n",
        "Clique (decision version) is NP-complete\n",
        "\n",
        "Traveling Salesperson Problem (decision version) is NP-complete\n",
        "\n",
        "Thus, all problems in this group are NP-complete.\n",
        "\n",
        "6. Cryptography, factoring large integers\n",
        "\n",
        "Factoring large integers is believed to be computationally hard, but it is not known to be NP-complete.\n",
        "\n",
        "Factoring belongs to NP, and also to NP-intermediate (assuming P ≠ NP).\n",
        "Many cryptographic systems rely on problems believed to be hard but not proven NP-complete.\n",
        "\n",
        "Thus, these problems are typically classified as NP (but not known NP-complete).\n",
        "\n",
        "7. Halting Problem, Busy Beaver\n",
        "\n",
        "The Halting Problem is undecidable: there is no algorithm that can solve it for all inputs.\n",
        "The Busy Beaver problem grows faster than any computable function and is also undecidable.\n",
        "\n",
        "Therefore, these problems are not in P, not in NP, and are uncomputable.\n",
        "\n",
        "Problem 2. Introduction to Bayes’ Theorem (3/10 pts)\n",
        "\n",
        "We are given:\n",
        "\n",
        "Disease prevalence: 0.1%\n",
        "\n",
        "Test accuracy: 99% sensitivity and 99% specificity\n",
        "\n",
        "Test result: positive\n",
        "\n",
        "Although the test is highly accurate, the disease is extremely rare. This means that among all positive test results, many come from healthy people simply because there are far more healthy people than sick people.\n",
        "\n",
        "Out of 1,000 people:\n",
        "\n",
        "About 1 person actually has the disease\n",
        "\n",
        "About 999 people do not\n",
        "\n",
        "The test correctly identifies almost all sick people, but it also incorrectly flags about 1% of healthy people as positive. This results in many false positives compared to true positives.\n",
        "\n",
        "As a result, when a patient tests positive, the probability that they actually have the disease is only about 9%.\n",
        "\n",
        "This phenomenon is known as the base rate fallacy, where ignoring the rarity of the disease leads to overestimating the reliability of a positive test result.\n",
        "\n",
        "Problem 3. Introduction to Shannon Entropy (3/10 pts)\n",
        "\n",
        "Shannon entropy measures the average amount of information, or surprise, produced by a random source.\n",
        "\n",
        "Coin A: Fair coin (50% heads)\n",
        "\n",
        "A fair coin produces heads and tails with equal probability.\n",
        "Each outcome is equally surprising.\n",
        "\n",
        "This maximizes uncertainty, and therefore the entropy is 1 bit.\n",
        "Each flip provides one full bit of information.\n",
        "\n",
        "Coin B: Biased coin (99% heads)\n",
        "\n",
        "This coin almost always produces heads.\n",
        "Seeing heads is not surprising at all.\n",
        "\n",
        "Because the outcome is highly predictable, the uncertainty is very low.\n",
        "The entropy is therefore very small, about 0.08 bits.\n",
        "\n",
        "Coin C: Rare heads (1%)\n",
        "\n",
        "This coin almost always produces tails.\n",
        "When heads appears, it is extremely surprising.\n",
        "\n",
        "However, because heads occurs so rarely, the average uncertainty per flip is still low.\n",
        "\n",
        "Thus, despite the huge surprise of a rare event, the entropy remains low overall.\n",
        "\n",
        "Why a fair coin is worth 1 bit, but a 99% biased coin is not\n",
        "\n",
        "A fair coin gives maximum uncertainty before each flip, so it carries the maximum amount of information.\n",
        "\n",
        "A highly biased coin is very predictable, so each flip gives little new information on average. Even though rare events are surprising, they do not occur often enough to increase the average information content."
      ],
      "metadata": {
        "id": "STxsm77xFIRa"
      }
    }
  ]
}